{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df52bb6",
   "metadata": {},
   "source": [
    "# Zero Shot Classification\n",
    "> This shows how to use both zero shot classification and answer questions referring to data from a linkedin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f71087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b2c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c3e61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.3 MB 36.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.11.0 tenacity-8.1.0\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b76af2",
   "metadata": {},
   "source": [
    "#### These are the requirements to do this NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daa1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import pipeline\n",
    "from fastai.tabular.all import *\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d89ccb",
   "metadata": {},
   "source": [
    "## Create a classifier to run \"zero-shot\" classification\n",
    "    > Here we'll use the hugging face transformers `pipeline` to use the pretrained zero-shot-classification \"auto-model.\"  This instantiates a class and automatically uses the bart-large-mnli model to classify how relevent different topics are to any given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12b308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f40469bb934bd887a0c99286c808fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066b19aadc6747c0b7621062b0e59215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47707ec1895c40f68b5f1c6998e348e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d3e086df0b4db6b7ef551977f91861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a4429556684a73a5bc71ab135566b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0932103f212f41edad2599cd50351011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba764ad",
   "metadata": {},
   "source": [
    "### Topic Relevance Example 1\n",
    ">How relevant are the following topics: Politics, Public Health, Economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5847eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Who are you voting for in 2022?', 'labels': ['politics', 'economics', 'public health'], 'scores': [0.9570426940917969, 0.023699436336755753, 0.019257841631770134]}\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Who are you voting for in 2022?\"\n",
    "candidate_labels = [\"politics\", \"public health\", \"economics\"]\n",
    "\n",
    "print(classifier(sequence, candidate_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f5607",
   "metadata": {},
   "source": [
    "### Topic Relevance Example 2\n",
    ">Use this on data from a Linkedin dataset to see if linkedin people are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba761f98",
   "metadata": {},
   "source": [
    "\n",
    "Bring in a Linkedin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8007332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('..')\n",
    "df = pd.read_csv(path/'linkedin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0489439",
   "metadata": {},
   "source": [
    "Create a column with all info to easily feed into the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b52957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: An experienced HR professional,  HR mentor and Coach , Talent advisory and HR strategist... see more; Experience: Senior Vice President & Head of HRCompany NameSamsung Electronics India LimitedDates EmployedJan 2018 â€“ PresentEmployment Duration2 yrs 3 mosLocationGurgaon, Haryana, IndiaVice President Franchise capability building and business transformationCompany NameCoca-Cola India a...\n"
     ]
    }
   ],
   "source": [
    "df.fillna('',inplace=True) #fill all na with ''\n",
    "#create input col to feed into the models\n",
    "df['input'] = 'description: ' + df.description+'; Experience: '+df.Experience+ '; Name: '+ df.Name+'; position: '+df.position+'; location: '+df.location+ '; skills: '+df.skills+ '; clean_skills: '+df.clean_skills\n",
    "df.input = df.input.astype(str)\n",
    "df.input = df.input.str.replace('\\\\n',' ',regex=False);  print(str(df.input[0][:400])+'...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd16221",
   "metadata": {},
   "source": [
    "Create a list of topics/categories.  We'll use th emodel to check how relevant each topic/category is to each person.  In this case each person is text entry from the column `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb6010c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"first five categories: ['HR', 'Designing', 'Managment', 'Information Technology', 'Education']\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = df.category.unique().tolist()\n",
    "candidate_labels.extend(['US','India']); 'first five categories: '+str(candidate_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be28b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def analyze_one(df:pd.DataFrame, # dataframe with df.input\n",
    "                candidate_labels, index ):\n",
    "    i=index\n",
    "    sequence = df.input[i]\n",
    "    answer = classifier(sequence, candidate_labels)\n",
    "    dfo = pd.DataFrame(answer)\n",
    "    dfo.sort_values('scores',inplace=True)\n",
    "    fig = px.bar(dfo, x=\"scores\", y=\"labels\", orientation='h')\n",
    "    print(dfo.sequence[0])\n",
    "    \n",
    "    print('Actual Category: '+str(df.category[i]))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676059f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_one(df,candidate_labels,index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3378cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_one(df,candidate_labels,index=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a89c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_one(df,candidate_labels,index=421)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e65331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('category').Name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc1f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.category=='Agricultural'].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c9771",
   "metadata": {},
   "source": [
    "try questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "538e537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17939401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"description: Over 18 Years of experience in IT /ITES  / BPO with leading global OrganizationsHave a passion for working on great products, enthusiastic about #UserExperience #SaaS #HRTech #Bots #Io...\\n            see more; Experience: Company NameEXLTotal Duration6 yrs 4 mosTitleVice President - Head of Digital HR Technologies and HR Operations/ shared servicesDates EmployedJul 2018 â€“ PresentEmployment Duration1 yr 9 mosLocationNoida Area, IndiaHave a passion for working on great products, enthusiastic about #UserExperience #SaaS #HRTech #Bots #IoT #Gadgets, #Mobileapps, #ERP... Strong experience in managing Transformative Business HR IT initiatives in a Global Shared Service environmentTitleSenior Assistant Vice President - Human ResourcesDates EmployedDec 2013 â€“ Jun 2018Employment Duration4 yrs 7 mosTitleVice President - Head of Digital HR Technologies and HR Operations/ shared servicesDates EmployedJul 2018 â€“ PresentEmployment Duration1 yr 9 mosLocationNoida Area, IndiaHave a passion for working on great products, enthusiastic about #UserExperience #SaaS #HRTech #Bots #IoT #Gadgets, #Mobileapps, #ERP... Strong experience in managing Transformative Business HR IT initiatives in a Global Shared Service environmentT; Name: Rakesh Kumar; position: Vice President - Digital HR Transformation Lead, Global HR Operations / Shared Services and HR Technologies; location: Central Delhi, Delhi, India; skills: [' Team Management ', ' Human Resources ', ' Employee Engagement ', ' Talent Acquisition ', ' Deferred Compensation ', ' ERP ', ' SDLC ', ' HR Consulting ', ' Change Management ', ' Strategic HR ', ' Business Process Improvement ', ' MIS ', ' HRIS ', ' PeopleSoft ', ' Cognos ', ' Ma\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.input[idx][:(int(.75 *len(df.input[idx])))]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2664d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# text = text\n",
    "\n",
    "# questions = [\"What is the persons name?\" ,\"What companies has this person worked with?\",\"Do they work in HR?\"\n",
    "# ]\n",
    "\n",
    "# for question in questions:\n",
    "#     inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "#     input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "#     outputs = model(**inputs)\n",
    "#     answer_start_scores = outputs.start_logits\n",
    "#     answer_end_scores = outputs.end_logits\n",
    "\n",
    "#     # Get the most likely beginning of answer with the argmax of the score\n",
    "#     answer_start = torch.argmax(answer_start_scores)\n",
    "#     # Get the most likely end of answer with the argmax of the score\n",
    "#     answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "#     answer = tokenizer.convert_tokens_to_string(\n",
    "#         tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
    "#     )\n",
    "\n",
    "#     print(f\"Question: {question}\")\n",
    "#     print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2b68587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efe34411f4940bcbaa109d6cc087267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f5ab9e2deb44eabb66136350e3ac09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190f5582b3664e2c8fdd6e3dfe2cd224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a982093167b4805bf0e82b1feac80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ff278ef1514376ae8c2fe7a874c5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
      "Answer: over 32 +\n",
      "Question: What does ðŸ¤— Transformers provide?\n",
      "Answer: general - purpose architectures\n",
      "Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
      "Answer: tensorflow 2. 0 and pytorch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "text = r\"\"\"\n",
    "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "TensorFlow 2.0 and PyTorch.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
    "    \"What does ðŸ¤— Transformers provide?\",\n",
    "    \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_start = torch.argmax(answer_start_scores)\n",
    "    # Get the most likely end of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(\n",
    "        tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
    "    )\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02dab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
